{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from analytics_utils.util.qubole import run_hive\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(model_id, omni_model_id, pid, start_date, end_date):\n",
    "    \n",
    "    s_date = start_date.replace('-', '') \n",
    "    e_date = end_date.replace('-', '')\n",
    "    \n",
    "    query1 = \"\"\"\n",
    "    DROP TABLE IF EXISTS tmp_seed_{pid}_{s_date}_{e_date};\n",
    "    CREATE TABLE IF NOT EXISTS tmp_seed_{pid}_{s_date}_{e_date} AS\n",
    "    SELECT DISTINCT hhid\n",
    "    FROM core_shared.transaction\n",
    "    WHERE provider_id = {pid}\n",
    "    AND txn_type = 'P'\n",
    "    AND total_amount > 0\n",
    "    AND txn_dt >= date '{start_date}'\n",
    "    AND txn_dt < date '{end_date}'\n",
    "    ;\n",
    "\n",
    "    DROP TABLE IF EXISTS tmp_back_{pid}_{s_date}_{e_date};\n",
    "    CREATE TABLE IF NOT EXISTS tmp_back_{pid}_{s_date}_{e_date} AS\n",
    "    SELECT u.hhid as hhid, CASE WHEN s.hhid IS NULL THEN 0 ELSE 1 END AS response\n",
    "    FROM dsmodeling.extract_hhids u\n",
    "    LEFT JOIN tmp_seed_{pid}_{s_date}_{e_date} s on u.hhid = s.hhid\n",
    "    ;\n",
    "\n",
    "    \"\"\".format(\n",
    "        pid = pid,\n",
    "        start_date = start_date,\n",
    "        end_date = end_date,\n",
    "        s_date = s_date,\n",
    "        e_date = e_date\n",
    "    )\n",
    "    \n",
    "    run_hive(query1, token='zarFf9MKQiandxqBeD751rw5qikvnMyjVwhDrGyJqfm8o1KdLdo4R36btaNfmXAG', return_data=False)      \n",
    "\n",
    "    query2 = \"\"\"\n",
    "    SELECT * FROM tmp_back_{pid}_{s_date}_{e_date}\n",
    "    ;\n",
    "    \"\"\".format(\n",
    "        pid = pid,\n",
    "        s_date = s_date,\n",
    "        e_date = e_date\n",
    "    )\n",
    "    \n",
    "    response_df = run_hive(query2, token='zarFf9MKQiandxqBeD751rw5qikvnMyjVwhDrGyJqfm8o1KdLdo4R36btaNfmXAG', return_data=True)      \n",
    "    response_df.columns = ['hhid', 'response']\n",
    "\n",
    "    query3 = \"\"\"\n",
    "    SELECT hhid, score FROM dsmodeling.ensemble_score_{model_id}_0;\n",
    "    \"\"\".format(\n",
    "        model_id = model_id\n",
    "    )\n",
    "    score_df = run_hive(query3, token='zarFf9MKQiandxqBeD751rw5qikvnMyjVwhDrGyJqfm8o1KdLdo4R36btaNfmXAG', return_data=True)      \n",
    "    score_df.columns = ['hhid', 'score']\n",
    "\n",
    "    query4 = \"\"\"\n",
    "    SELECT hhid, score FROM dsmodeling.ensemble_score_{omni_model_id}_0;\n",
    "    \"\"\".format(\n",
    "        omni_model_id = omni_model_id\n",
    "    )\n",
    "    score_omni_df = run_hive(query4, token='zarFf9MKQiandxqBeD751rw5qikvnMyjVwhDrGyJqfm8o1KdLdo4R36btaNfmXAG', return_data=True)      \n",
    "    score_omni_df.columns = ['hhid', 'score']\n",
    "\n",
    "    \n",
    "    back_df = response_df.merge(score_df, how = 'inner', on = 'hhid')\n",
    "    back_omni_df = response_df.merge(score_omni_df, how = 'inner', on = 'hhid')\n",
    "    \n",
    "    return back_df, back_omni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTop(top_val, back_df, back_omni_df):\n",
    "    back_top_df = back_df.nlargest(top_val, 'score')\n",
    "    back_omni_top_df = back_omni_df.nlargest(top_val, 'score')\n",
    "    return back_top_df, back_omni_top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC AUC and Precision Recall AUC ###\n",
    "def plot_model_metrics_2(df_1, df_2, penetration_index, note, campaign_note, brand):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 4.5))\n",
    "\n",
    "    # ROC AUC \n",
    "    from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss, roc_curve\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    import bisect\n",
    "    import pylab as pl\n",
    "    import sys\n",
    "    with PdfPages(note[1:]+'_'+campaign_note+'.pdf') as pdf:   \n",
    "        from matplotlib.gridspec import GridSpec\n",
    "        gs = GridSpec(9, 1)\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        roc_auc_1 = roc_auc_score(df_1['response'], df_1['score'])\n",
    "        roc_auc_2 = roc_auc_score(df_2['response'], df_2['score'])\n",
    "        fpr_1, tpr_1, _1 = roc_curve(df_1['response'], df_1['score'])\n",
    "        fpr_2, tpr_2, _2 = roc_curve(df_2['response'], df_2['score'])\n",
    "        ax1.plot(fpr_1, tpr_1, 'b-', alpha = 0.5, label='without omni (area = %0.3f)' % roc_auc_1)\n",
    "        ax1.plot(fpr_2, tpr_2, 'r', alpha = 0.5, label='with omni (area = %0.3f)' % roc_auc_2)\n",
    "        ax1.plot([0, 1], [0, 1], 'k--', alpha = 0.5)\n",
    "        ax1.axis(xmin = 0.0, xmax = 1.0, ymin = 0.0, ymax = 1.05)\n",
    "        ax1.set_xlabel('False Positive Rate (1 - Specifity)')\n",
    "        ax1.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "        ax1.set_title('ROC Curve ' + note)\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "\n",
    "        #PRECISION (BTR)\n",
    "        segments = 10\n",
    "        top_segments = 1\n",
    "        segment_percentile = [i for i in range(10, 110, segments)]\n",
    "\n",
    "        '''model1'''\n",
    "        df_sorted_1 = df_1.sort_values('score', ascending = False)\n",
    "        df_sorted_1.reset_index(drop = 1, inplace = True)\n",
    "\n",
    "        segment_size = np.round(len(df_sorted_1)/segments)\n",
    "        segment_precision_1 = []\n",
    "        for i in (np.array(range(segments)) + 1)*segment_size:\n",
    "            segment_precision_1.append(round((df_sorted_1.loc[:i, 'response'].mean())/penetration_index, 3))\n",
    "        cumulative_precision_1 = segment_precision_1[-1]\n",
    "        \n",
    "        '''model2'''\n",
    "        df_sorted_2 = df_2.sort_values('score', ascending = False)\n",
    "        df_sorted_2.reset_index(drop = 1, inplace = True)\n",
    "\n",
    "        segment_size = np.round(len(df_sorted_2)/segments)\n",
    "        segment_precision_2 = []\n",
    "        for i in (np.array(range(segments)) + 1)*segment_size:\n",
    "            segment_precision_2.append(round((df_sorted_2.loc[:i, 'response'].mean())/penetration_index, 3))\n",
    "        cumulative_precision_2 = segment_precision_2[-1]\n",
    "\n",
    "        segment_precision_frac = [round(segment_precision_2[i]/segment_precision_1[i],4) for i in range(len(segment_precision_1))]\n",
    "\n",
    "        print \"The segment precision for the base model:\" + str(segment_precision_1)\n",
    "        print \"The segment precision for the model with omni data:\" + str(segment_precision_2)\n",
    "\n",
    "        for i in range(1,3):\n",
    "            ax2.text((i-1)*10, segment_precision_2[i-1]+0.05, str((segment_precision_frac[i-1]-1)*100)+'%', color='black')\n",
    "            x1, y1, x2, y2 = [i*10, i*10], [0, segment_precision_2[i-1]], [0, i*10], [segment_precision_2[i-1], segment_precision_2[i-1]]\n",
    "            ax2.plot(x1, y1, 'k--', alpha = 0.5)\n",
    "            ax2.plot(x2, y2, 'k--', alpha = 0.5)\n",
    "            plt.plot(segment_percentile[i-1], segment_precision_2[i-1], marker='o', markersize=3, color=\"red\")\n",
    "\n",
    "        ax2.plot(segment_percentile, segment_precision_1, 'b-', alpha = 0.5, label = 'without omni')\n",
    "        ax2.plot(segment_percentile, segment_precision_2, 'r', alpha = 0.5, label = 'with omni')\n",
    "        ax2.axis(xmin = 0, xmax = 100, ymin = 0.00, ymax = max(max(segment_precision_1, segment_precision_2))+0.1)\n",
    "        ax2.set_xlabel('Segment Percentile')\n",
    "        ax2.set_ylabel('BTRi')\n",
    "        ax2.set_title('Lift Table'+note)\n",
    "        ax2.legend(loc=\"lower middle\")\n",
    "        \n",
    "    \n",
    "        #SCALE INCREASE\n",
    "        scale_segments = 100\n",
    "        scale_segment_size = np.round(len(df_sorted_2)/scale_segments)\n",
    "        scale_segment_precision_2 = sys.maxint\n",
    "        depth = 7\n",
    "        \n",
    "        while (segment_precision_1[0] < scale_segment_precision_2):\n",
    "            scale_segment_precision_2 = round((df_sorted_2.loc[:depth*scale_segment_size, 'response'].mean())/penetration_index, 3)\n",
    "            depth += 0.1\n",
    "\n",
    "        txt = '''\n",
    "        The BTRi for the base model at 10% segment : {precision_segment_1}\n",
    "        The BTRi for the model with omni data at 10% segment : {precision_segment_2} ({BTRi_pct_1}% increase)\n",
    "        The cumulative BTRi for the base model: {cumulative_precision_1}\n",
    "        The cumulative BTRi for the model with omni data: {cumulative_precision_2} ({BTRi_pct}% increase)\n",
    "        The scale of direct mail models (at comparable BTRi of segment 1) is changed by {scale_pct}%\n",
    "        '''.format(\n",
    "        precision_segment_1 = round(segment_precision_1[0],2),\n",
    "        precision_segment_2 = round(segment_precision_2[0],2),\n",
    "        BTRi_pct_1 = round((segment_precision_frac[0]-1)*100,2),\n",
    "        cumulative_precision_1=cumulative_precision_1,\n",
    "        cumulative_precision_2=cumulative_precision_2,\n",
    "        BTRi_pct=round((cumulative_precision_2/cumulative_precision_1-1)*100,2),\n",
    "        scale_pct = round(depth-0.1-10,1)*100/10\n",
    "        )\n",
    "        \n",
    "        plt.text(0,-0.2,txt, transform=fig.transFigure, size=10)    \n",
    "        pdf.savefig(bbox_inches=\"tight\", pad_inches=0.5)\n",
    "        plt.close()\n"
   ]
  }
